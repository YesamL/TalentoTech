# ===============================
# ğŸ¤– Chatbot Mejorado con Streamlit y Caching - Calidad de SueÃ±o
# ===============================

import streamlit as st
import pandas as pd
import numpy as np
# time es Ãºtil para pausas cortas en la interacciÃ³n del bot
import time
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import MinMaxScaler
# Importaciones que no se usan en el frontend pero son parte del anÃ¡lisis original
# from sklearn.metrics import classification_report, confusion_matrix, cross_val_score

# ======================================
# 1. ğŸ“Œ Cargar datos y entrenar modelo (Cacheado)
# ======================================
@st.cache_resource # Carga y entrena solo una vez
def load_data_train_model(data_url: str):
    """Carga los datos desde una URL, entrena el modelo y fitea el scaler."""
    try:
        df = pd.read_csv(data_url)
        feature_columns = ['Age', 'Sleep Duration', 'Physical Activity Level', 'Stress Level']
        target_column = 'Quality of Sleep'

        # Asegurarse de que las columnas necesarias existan
        if not all(col in df.columns for col in feature_columns + [target_column]):
             missing = [col for col in feature_columns + [target_column] if col not in df.columns]
             st.error(f"Error: El archivo CSV no contiene las columnas necesarias. Faltan: {missing}")
             st.stop()

        X = df[feature_columns]
        y = df[target_column]

        # Escalado de caracterÃ­sticas: fit en todos los datos originales
        scaler = MinMaxScaler()
        scaler.fit(X)

        # DivisiÃ³n y entrenamiento del modelo (solo necesitamos el modelo entrenado)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        model = DecisionTreeClassifier(random_state=42)
        model.fit(X_train, y_train)

        st.success("Datos cargados y modelo entrenado. Â¡Listo para chatear!") # Mensaje de confirmaciÃ³n

        return model, scaler, feature_columns

    except Exception as e:
        st.error(f"OcurriÃ³ un error al cargar datos o entrenar el modelo: {e}")
        st.stop() # Detiene la aplicaciÃ³n en caso de error grave

# URL del dataset en GitHub
DATA_URL = 'https://raw.githubusercontent.com/YesamL/TalentoTech/main/data/Sleep_health_and_lifestyle_dataset.csv'

# Cargar modelo, scaler y columnas usando la funciÃ³n cacheada
model, scaler, feature_columns = load_data_train_model(DATA_URL)

# --- LÃ³gica de Consejos (Adaptada para mensajes de chat) ---
def get_advice_messages(predicted_score: float, user_inputs: dict) -> list[str]:
    """Genera una lista de mensajes de consejos basados en la predicciÃ³n y inputs."""
    messages = []
    messages.append("Basado en mi predicciÃ³n y tus datos:")

    # Acceder a los datos del usuario directamente desde el diccionario
    edad = user_inputs[feature_columns[0]]
    horas_sueno = user_inputs[feature_columns[1]]
    actividad_fisica = user_inputs[feature_columns[2]]
    nivel_estres = user_inputs[feature_columns[3]]

    if predicted_score >= 8:
        messages.append("âœ¨ Â¡Excelente! Tu calidad de sueÃ±o es alta. ğŸ˜´âœ¨")
        messages.append("âœ… ContinÃºa con tus hÃ¡bitos saludables de sueÃ±o, actividad fÃ­sica y manejo del estrÃ©s.")
        messages.append("ğŸ›Œ Mantener un horario de sueÃ±o regular es clave.")
    elif predicted_score >= 6:
        messages.append("ğŸ‘ Tu calidad de sueÃ±o es aceptable, pero podrÃ­as mejorarlo un poco.")
        messages.append("Ideas para mejorar:")
        if horas_sueno < 7:
            messages.append(f"- Intenta dormir entre 7 y 9 horas por noche (actualmente ~{horas_sueno:.1f}h).")
        if actividad_fisica < 150: # Valor de referencia (ej: minutos moderados por semana)
             messages.append(f"- Aumenta tu actividad fÃ­sica semanal (actualmente ~{actividad_fisica:.0f} min/sem). Busca al menos 150 min moderados.")
        if nivel_estres > 5: # Valor de referencia
            messages.append(f"- Explora tÃ©cnicas de manejo del estrÃ©s (nivel actual ~{nivel_estres:.1f}).")
        messages.append("âœ¨ Establece una rutina relajante antes de acostarte.")
    else: # predicted_score < 6
        messages.append("âš ï¸ Tu calidad de sueÃ±o parece baja. Â¡Es importante tomar medidas! ğŸŒ™")
        messages.append("Pasos recomendados:")
        if horas_sueno < 7:
            messages.append(f"- Prioriza aumentar tus horas de sueÃ±o (actualmente ~{horas_sueno:.1f}h). Intenta horarios regulares.")
        if actividad_fisica < 150:
             messages.append(f"- La actividad fÃ­sica regular es vital (actualmente ~{actividad_fisica:.0f} min/sem). Busca incorporar ejercicio diario.")
        if nivel_estres > 5:
            messages.append(f"- Trabaja en reducir tu estrÃ©s diario (nivel actual ~{nivel_estres:.1f}). Busca apoyo o estrategias efectivas.")
        messages.append("ğŸ  Revisa tu higiene del sueÃ±o: habitaciÃ³n oscura, silenciosa y fresca.")
        messages.append("ğŸš« Evita cafeÃ­na, alcohol y pantallas electrÃ³nicas antes de dormir.")
        messages.append("ğŸ‘©â€âš•ï¸ Si los problemas persisten, considera consultar a un mÃ©dico o especialista en sueÃ±o.")

    return messages


# ======================================
# 2. ğŸ“Œ Streamlit App en forma de Chatbot - LÃ³gica de InteracciÃ³n
# ======================================

st.title("ğŸ¤– Asistente Virtual de Calidad del SueÃ±o ğŸ’¤")
st.caption("Impulsado por datos de TalentoTech")

# Inicializar estado de sesiÃ³n (si aÃºn no existen)
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_state" not in st.session_state:
    # Estados: inicio, pidiendo_nombre, pidiendo_edad, pidiendo_sueno, ..., recolectando, completo, preguntando_reiniciar, fin
    st.session_state.chat_state = "inicio"
if "user_data_collector" not in st.session_state:
    st.session_state.user_data_collector = {}
if "user_name" not in st.session_state:
    st.session_state.user_name = ""

# --- Mostrar mensajes histÃ³ricos ---
# Este bucle se ejecuta en cada rerun para mostrar toda la conversaciÃ³n
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- LÃ³gica Principal del Chatbot ---

# LÃ³gica del primer mensaje y cambio de estado inicial
if st.session_state.chat_state == "inicio":
    initial_message = "Â¡Hola! ğŸ‘‹ Soy tu asistente personal para analizar y mejorar tu sueÃ±o. Â¿CÃ³mo te llamas?"
    with st.chat_message("assistant"):
        st.markdown(initial_message)
    st.session_state.messages.append({"role": "assistant", "content": initial_message})
    st.session_state.chat_state = "pidiendo_nombre" # Siguiente estado


# Usar st.chat_input para obtener la entrada del usuario
# Este widget solo aparece si no se llama a st.stop()
user_input = st.chat_input("Escribe aquÃ­ tu respuesta...")

if user_input:
    # AÃ±adir la entrada del usuario a la historia inmediatamente
    st.session_state.messages.append({"role": "user", "content": user_input})

    # --- Procesar la entrada segÃºn el estado actual ---
    current_state = st.session_state.chat_state
    user_data = st.session_state.user_data_collector
    user_name = st.session_state.user_name
    next_state = current_state # Por defecto, el estado no cambia a menos que sea exitoso
    bot_response = None # Mensaje del bot a mostrar despuÃ©s de procesar input
    process_input_success = False # Bandera para saber si el input actual fue vÃ¡lido y procesado

    # Diccionario para mapear estados a preguntas y nombres de columnas
    questions = {
        "pidiendo_edad": (f"{user_name}, Â¿quÃ© edad tienes? ğŸ‚ ({feature_columns[0]})", feature_columns[0]),
        "pidiendo_sueno": (f"{user_name}, Â¿cuÃ¡ntas horas duermes normalmente por noche? ğŸ›ï¸ ({feature_columns[1]})", feature_columns[1]),
        "pidiendo_actividad": (f"{user_name}, Â¿cuÃ¡ntos minutos de actividad fÃ­sica haces por semana? ğŸƒâ€â™‚ï¸ ({feature_columns[2]})", feature_columns[2]),
        "pidiendo_estres": (f"{user_name}, en una escala del 1 al 10, Â¿cuÃ¡nto estrÃ©s sientes? ğŸ˜° ({feature_columns[3]})", feature_columns[3]),
    }

    # --- LÃ³gica de Estados ---
    if current_state == "pidiendo_nombre":
        if len(user_input.strip()) > 0:
            user_name = user_input.strip().split()[0] # Tomar solo el primer nombre si hay varios
            st.session_state.user_name = user_name
            bot_response = f"Â¡Mucho gusto, {user_name}! ğŸ˜„ Ahora sÃ­, comencemos con las preguntas para tu predicciÃ³n. Â¿QuÃ© edad tienes? ğŸ‚ ({feature_columns[0]})"
            next_state = "pidiendo_edad"
            process_input_success = True
        else:
            bot_response = "Â¿No me dices tu nombre? No hay problema. Â¿Empezamos con las preguntas? Â¿QuÃ© edad tienes? ğŸ‚"
            st.session_state.user_name = "usuario" # Nombre por defecto
            next_state = "pidiendo_edad"
            process_input_success = True # Considerar como Ã©xito para avanzar

    elif current_state in ["pidiendo_edad", "pidiendo_sueno", "pidiendo_actividad", "pidiendo_estres"]:
        pregunta, col_name = questions[current_state]
        try:
            value = float(user_input)
            # Validaciones bÃ¡sicas
            if col_name == feature_columns[0] and (value <= 0 or value > 120): # Edad
                 raise ValueError("La edad debe ser entre 1 y 120 aÃ±os.")
            elif col_name == feature_columns[1] and (value <= 0 or value > 24): # SueÃ±o
                 raise ValueError("La duraciÃ³n del sueÃ±o debe ser positiva (horas).")
            elif col_name == feature_columns[2] and value < 0: # Actividad
                 raise ValueError("La actividad fÃ­sica no puede ser negativa.")
            elif col_name == feature_columns[3] and (value < 1 or value > 10): # EstrÃ©s
                 raise ValueError("El nivel de estrÃ©s debe ser un nÃºmero entre 1 y 10.")

            user_data[col_name] = value # Almacenar el valor validado
            process_input_success = True # Marcar como Ã©xito

            # Determinar el siguiente estado y la siguiente pregunta
            current_index = feature_columns.index(col_name)
            if current_index < len(feature_columns) - 1:
                next_col_name = feature_columns[current_index + 1]
                # Encontrar el estado que corresponde a la siguiente columna
                next_state = [state for state, info in questions.items() if info[1] == next_col_name][0]
                next_question, _ = questions[next_state]
                bot_response = f"Entendido. {next_question}"
            else:
                # Todos los datos recolectados
                bot_response = f"Â¡Gracias, {user_name}! Ya tengo todos los datos necesarios. PermÃ­teme un momento para hacer la predicciÃ³n."
                next_state = "recolectando" # Estado intermedio antes de 'completo'

        except ValueError as e:
            # Error especÃ­fico de valor o tipo
            bot_response = f"ğŸ¤” Ups. Parece que '{user_input}' no es una respuesta vÃ¡lida para la pregunta sobre {col_name.lower().replace(' level', '')}. {e} Por favor, intenta de nuevo con un nÃºmero."
            process_input_success = False # Mantener estado actual

        except Exception as e:
            # Otros posibles errores
            bot_response = f"âŒ OcurriÃ³ un error inesperado al procesar tu respuesta sobre {col_name.lower()}: {e}"
            process_input_success = False # Mantener estado actual


    # --- Si llegamos al estado 'recolectando' despuÃ©s de un input exitoso, hacemos la predicciÃ³n ---
    # Usamos un estado intermedio para asegurar que el Ãºltimo mensaje de confirmaciÃ³n se muestre ANTES de la predicciÃ³n
    if current_state == "recolectando" and process_input_success:
        # Mostrar el Ãºltimo mensaje de confirmaciÃ³n si existe
        if bot_response:
             with st.chat_message("assistant"):
                 st.markdown(bot_response)
             st.session_state.messages.append({"role": "assistant", "content": bot_response})
             # Limpiar el bot_response para que no se duplique abajo
             bot_response = None
        # Importante: No cambiar next_state aÃºn, la predicciÃ³n lo harÃ¡

        with st.spinner("Analizando tus datos..."):
             time.sleep(1.5) # Simula tiempo de procesamiento

             # Crear DataFrame para predicciÃ³n desde los datos recolectados
             user_data_df = pd.DataFrame([user_data], columns=feature_columns)

             # Escalar datos del usuario
             # Usamos transform() con el scaler que fue fit() en load_data_train_model
             user_data_scaled = scaler.transform(user_data_df)

             # Realizar la predicciÃ³n
             predicted_quality = model.predict(user_data_scaled)[0]

             # Mostrar predicciÃ³n
             prediction_message = f"ğŸŒŸ {user_name}, segÃºn mis cÃ¡lculos, tu calidad de sueÃ±o es: **{int(predicted_quality)}**"
             with st.chat_message("assistant"):
                 st.markdown(prediction_message)
             st.session_state.messages.append({"role": "assistant", "content": prediction_message})

             # Obtener y mostrar consejos
             advice_messages = get_advice_messages(predicted_quality, user_data_df)
             with st.chat_message("assistant"):
                 st.markdown("ğŸ’¡ AquÃ­ tienes algunos consejos para ti:") # Encabezado de consejos
             st.session_state.messages.append({"role": "assistant", "content": "ğŸ’¡ AquÃ­ tienes algunos consejos para ti:"})
             # Mostrar cada consejo como un mensaje separado para mejor lectura
             for i, advice_msg in enumerate(advice_messages):
                 # Opcional: aÃ±adir un pequeÃ±o retraso entre consejos
                 # if i > 0: time.sleep(0.2) # Pausa corta
                 with st.chat_message("assistant"):
                     st.markdown(advice_msg)
                 st.session_state.messages.append({"role": "assistant", "content": advice_msg})

             # Preguntar si quiere otra predicciÃ³n o terminar
             final_message = f"Â¿Te gustarÃ­a hacer otra predicciÃ³n ('empezar') o prefieres terminar ('salir')?"
             with st.chat_message("assistant"):
                  st.markdown(final_message)
             st.session_state.messages.append({"role": "assistant", "content": final_message})

             # Resetear el estado y datos para una posible nueva conversaciÃ³n
             next_state = "preguntando_reiniciar"
             st.session_state.user_data_collector = {} # Limpiar datos recolectados


    elif current_state == "preguntando_reiniciar":
         if "empezar" in user_input.lower() or "si" in user_input.lower() or "otra" in user_input.lower():
             bot_response = f"Â¡Excelente! Empecemos de nuevo. Â¿QuÃ© edad tienes, {user_name}? ğŸ‚ ({feature_columns[0]})"
             next_state = "pidiendo_edad"
             st.session_state.user_data_collector = {} # Asegurarse de que estÃ© limpio
             st.session_state.messages = [] # Opcional: Limpiar la conversaciÃ³n anterior al reiniciar
             st.session_state.initial_message_shown = True # Mostrar el primer mensaje de pregunta directamente
         elif "salir" in user_input.lower() or "no" in user_input.lower() or "terminar" in user_input.lower():
             bot_response = f"De acuerdo, {user_name}. Â¡Que tengas un excelente descanso y un buen dÃ­a! AdiÃ³s. ğŸ‘‹"
             next_state = "fin"
         else:
             bot_response = f"No entendÃ­. Â¿Quieres hacer otra predicciÃ³n ('empezar') o terminar ('salir'), {user_name}?"
             # next_state remains 'preguntando_reiniciar'


    # --- Actualizar el estado y datos si el procesamiento del input fue exitoso ---
    # ExcepciÃ³n: El estado 'recolectando' maneja su propia transiciÃ³n
    if process_input_success and current_state != "recolectando":
         st.session_state.chat_state = next_state
         st.session_state.user_data_collector = user_data # Guardar datos actualizados
    # Si el estado actual *era* 'recolectando' y tuvo Ã©xito, ya se cambiÃ³ el estado a 'preguntando_reiniciar' dentro de ese bloque

    # --- Mostrar la respuesta del bot generada (si existe) ---
    # Excluimos el mensaje del estado 'recolectando' que se muestra dentro de su bloque
    if bot_response and current_state != "recolectando":
        with st.chat_message("assistant"):
            st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})

    # --- Manejar el estado final ---
    if st.session_state.chat_state == "fin":
        st.balloons() # Opcional: aÃ±adir algo visual al finalizar
        st.stop() # Detiene la ejecuciÃ³n del script Streamlit aquÃ­.